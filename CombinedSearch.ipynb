{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPwSNV6CqXws"
      },
      "outputs": [],
      "source": [
        "# Colab Notebook: JSON Knowledge Base Chatbot with Live Editable System Prompt\n",
        "\n",
        "# When run you will need to enter an openAI API key that can be provided for testing purposes\n",
        "# It will then ask you to load the json knowledge base\n",
        "\n",
        "# The system prompt does not need to be changed. You can edit it if for instance you want the system to be biased towards \"Cybernetics\".\n",
        "# This can be added in plain text\n",
        "\n",
        "# When you ask the question you will recieve a few responses.. these will include infrormation about the pdfs selected for use through keyword and semantic search.\n",
        "# You will then recieve the chatr response that is based on the selected PDFs and the system prompt\n",
        "\n",
        "# üõ†Ô∏è Install dependencies\n",
        "!pip install -q openai PyMuPDF requests numpy scikit-learn psutil ipywidgets pillow pdf2image pytesseract\n",
        "\n",
        "# üì¶ Imports\n",
        "import os\n",
        "import json\n",
        "import fitz  # PyMuPDF\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "from google.colab import files\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "import psutil\n",
        "import re\n",
        "import html\n",
        "from functools import lru_cache\n",
        "\n",
        "# Enable widgets in Colab\n",
        "try:\n",
        "    from google.colab import output as colab_output\n",
        "    colab_output.enable_custom_widget_manager()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# ----------------------------\n",
        "# Global state\n",
        "# ----------------------------\n",
        "chat_history_html = \"\"\n",
        "api_key_ready = False\n",
        "\n",
        "# ----------------------------\n",
        "# API key UI\n",
        "# ----------------------------\n",
        "api_key_input = widgets.Password(\n",
        "    description='API Key:',\n",
        "    placeholder='Enter your OpenAI API key',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "submit_button = widgets.Button(description='Save API Key', button_style='info')\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def set_api_key(_):\n",
        "    global api_key_ready\n",
        "    with output_area:\n",
        "        clear_output()\n",
        "        if api_key_input.value.strip() == \"\":\n",
        "            display(HTML(\"<b style='color:#e53935;'>‚ùå Please enter a valid API key.</b>\"))\n",
        "        else:\n",
        "            os.environ[\"OPENAI_API_KEY\"] = api_key_input.value.strip()\n",
        "            api_key_ready = True\n",
        "            display(HTML(\"<b style='color:#43a047;'>‚úÖ API key saved. You can continue.</b>\"))\n",
        "\n",
        "submit_button.on_click(set_api_key)\n",
        "display(HTML(\"<h3>üîë Enter your OpenAI API key to continue:</h3>\"))\n",
        "display(api_key_input, submit_button, output_area)\n",
        "\n",
        "# ----------------------------\n",
        "# OpenAI client\n",
        "# ----------------------------\n",
        "def get_openai_client():\n",
        "    key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    try:\n",
        "        if (not key) and api_key_input.value:\n",
        "            key = api_key_input.value.strip()\n",
        "            if key:\n",
        "                os.environ[\"OPENAI_API_KEY\"] = key\n",
        "    except NameError:\n",
        "        pass\n",
        "    if not key:\n",
        "        raise ValueError(\"API key not set. Please enter your API key and try again.\")\n",
        "    return OpenAI(api_key=key)\n",
        "\n",
        "# ----------------------------\n",
        "# JSON loader with JSON-LD support\n",
        "# ----------------------------\n",
        "def normalise_to_list(obj):\n",
        "    if isinstance(obj, list):\n",
        "        return obj\n",
        "    if isinstance(obj, dict):\n",
        "        for k in [\"@graph\", \"graph\", \"data\", \"items\", \"entries\", \"documents\", \"records\"]:\n",
        "            if k in obj and isinstance(obj[k], list):\n",
        "                return obj[k]\n",
        "        return [obj]\n",
        "    raise ValueError(\"Unsupported JSON structure\")\n",
        "\n",
        "def upload_json():\n",
        "    display(HTML(\"<h3>üì• Upload your JSON knowledge base file...</h3>\"))\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise ValueError(\"No file uploaded.\")\n",
        "    json_file_path = next(iter(uploaded))\n",
        "    with open(json_file_path, \"r\") as f:\n",
        "        kb_raw = json.load(f)\n",
        "    kb = normalise_to_list(kb_raw)\n",
        "    display(HTML(f\"<b>‚úÖ Loaded {len(kb)} entries from {html.escape(json_file_path)}</b>\"))\n",
        "    return kb\n",
        "\n",
        "# ----------------------------\n",
        "# Summaries and embeddings\n",
        "# ----------------------------\n",
        "def entry_summary(entry):\n",
        "    for k in [\"summary\", \"abstract\", \"description\"]:\n",
        "        if isinstance(entry.get(k), str) and entry[k].strip():\n",
        "            return entry[k]\n",
        "    parts = []\n",
        "    for k in [\"title\", \"date\", \"datePublished\", \"author\", \"keywords\"]:\n",
        "        v = entry.get(k)\n",
        "        if isinstance(v, list):\n",
        "            parts.append(\" \".join(map(str, v)))\n",
        "        elif isinstance(v, str):\n",
        "            parts.append(v)\n",
        "    if not parts:\n",
        "        return json.dumps(entry)[:1000]\n",
        "    return \" | \".join(parts)\n",
        "\n",
        "def create_embeddings(kb):\n",
        "    client = get_openai_client()\n",
        "    display(HTML(\"<b>üîÑ Generating embeddings for entries...</b>\"))\n",
        "\n",
        "    def get_embedding(text):\n",
        "        resp = client.embeddings.create(\n",
        "            model=\"text-embedding-3-small\",\n",
        "            input=text if text else \"\"\n",
        "        )\n",
        "        return np.array(resp.data[0].embedding, dtype=np.float32)\n",
        "\n",
        "    summaries = [entry_summary(e) for e in kb]\n",
        "    summary_embeddings = np.stack([get_embedding(s) for s in summaries], axis=0)\n",
        "    display(HTML(\"<b>‚úÖ Embeddings created.</b>\"))\n",
        "    return summaries, summary_embeddings\n",
        "\n",
        "# ----------------------------\n",
        "# PDF fetch with cache and optional OCR\n",
        "# ----------------------------\n",
        "def maybe_install_ocr_deps():\n",
        "    import shutil\n",
        "    needs_poppler = shutil.which(\"pdftoppm\") is None\n",
        "    needs_tesseract = shutil.which(\"tesseract\") is None\n",
        "    if needs_poppler or needs_tesseract:\n",
        "        print(\"Installing OCR system packages. This may take a minute...\")\n",
        "        os.system(\"apt-get update -y >/dev/null 2>&1\")\n",
        "        if needs_poppler:\n",
        "            os.system(\"apt-get install -y poppler-utils >/dev/null 2>&1\")\n",
        "        if needs_tesseract:\n",
        "            os.system(\"apt-get install -y tesseract-ocr >/dev/null 2>&1\")\n",
        "\n",
        "@lru_cache(maxsize=256)\n",
        "def fetch_pdf_bytes(url):\n",
        "    if not url:\n",
        "        raise ValueError(\"Empty URL\")\n",
        "    raw_url = url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob\", \"\")\n",
        "    resp = requests.get(raw_url, timeout=60)\n",
        "    resp.raise_for_status()\n",
        "    return resp.content\n",
        "\n",
        "def extract_text_pymupdf(pdf_bytes):\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with fitz.open(stream=pdf_bytes, filetype=\"pdf\") as pdf_doc:\n",
        "            for page in pdf_doc:\n",
        "                text += page.get_text() or \"\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"[PDF parse error: {e}]\"\n",
        "\n",
        "def ocr_pdf_bytes(pdf_bytes):\n",
        "    try:\n",
        "        from pdf2image import convert_from_bytes\n",
        "        import pytesseract\n",
        "        pages = convert_from_bytes(pdf_bytes, fmt=\"png\", dpi=200)\n",
        "        texts = []\n",
        "        for img in pages:\n",
        "            texts.append(pytesseract.image_to_string(img))\n",
        "        return \"\\n\".join(texts)\n",
        "    except Exception as e:\n",
        "        return f\"[OCR error: {e}]\"\n",
        "\n",
        "def fetch_pdf_text(url, try_ocr=False):\n",
        "    try:\n",
        "        b = fetch_pdf_bytes(url)\n",
        "        text = extract_text_pymupdf(b)\n",
        "        if try_ocr:\n",
        "            if len(text.strip()) < 100:\n",
        "                ocr_text = ocr_pdf_bytes(b)\n",
        "                if len(ocr_text.strip()) > len(text.strip()):\n",
        "                    return ocr_text\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"[PDF fetch error: {e}]\"\n",
        "\n",
        "# ----------------------------\n",
        "# Helpers\n",
        "# ----------------------------\n",
        "stopwords = set(\"the and is it to for in of on with a an as at by from this that\".split())\n",
        "def extract_entities(text):\n",
        "    words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "    return [w for w in words if w not in stopwords and len(w) > 2]\n",
        "\n",
        "def keyword_score(entry, entities):\n",
        "    combined = \" \".join(str(entry.get(field, \"\")) for field in entry).lower()\n",
        "    return sum(combined.count(e) for e in entities)\n",
        "\n",
        "def print_memory_usage(conversation_history):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    ram_used_mb = process.memory_info().rss / (1024 * 1024)\n",
        "    vmem = psutil.virtual_memory()\n",
        "    colab_ram = vmem.used / (1024 * 1024)\n",
        "    colab_total_ram = vmem.total / (1024 * 1024)\n",
        "    display(HTML(f\"\"\"\n",
        "        <div style='border:1px solid #444; padding:6px; margin:6px; border-radius:6px; background:#222; color:#ccc; font-family:monospace;'>\n",
        "        üß† <b>Memory Stats:</b><br>\n",
        "        üîπ Process RAM: {ram_used_mb:.2f} MB<br>\n",
        "        üîπ Colab RAM: {colab_ram:.2f} MB / {colab_total_ram:.2f} MB<br>\n",
        "        üîπ Chat History Size: {len(json.dumps(conversation_history))/1024:.1f} KB\n",
        "        </div>\n",
        "    \"\"\"))\n",
        "\n",
        "# ----------------------------\n",
        "# Chat UI\n",
        "# ----------------------------\n",
        "def chat_ui(kb, summaries, summary_embeddings):\n",
        "    global chat_history_html\n",
        "    client = get_openai_client()\n",
        "\n",
        "    # Controls\n",
        "    base_system_prompt = \"You are a helpful assistant with access to a structured JSON knowledge base and linked PDFs.\"\n",
        "    bias_input = widgets.Text(\n",
        "        value=\"\",\n",
        "        placeholder='Optional bias theme, e.g. Cybernetics',\n",
        "        description='Bias:',\n",
        "        layout=widgets.Layout(width='100%')\n",
        "    )\n",
        "    system_prompt_input = widgets.Textarea(\n",
        "        value=base_system_prompt,\n",
        "        placeholder='Enter the base system prompt here...',\n",
        "        description='System Prompt:',\n",
        "        layout=widgets.Layout(width='100%', height='80px')\n",
        "    )\n",
        "    top_k_slider = widgets.IntSlider(value=2, min=1, max=10, step=1, description='Top K:')\n",
        "    kw_weight_slider = widgets.FloatSlider(value=0.5, min=0.0, max=2.0, step=0.1, description='Keyword weight:')\n",
        "    ctx_chars_slider = widgets.IntSlider(value=6000, min=1000, max=20000, step=500, description='Chars/doc:')\n",
        "    ocr_checkbox = widgets.Checkbox(value=False, description='Use OCR fallback for scanned PDFs')\n",
        "    show_mem_checkbox = widgets.Checkbox(value=False, description='Show memory stats after replies')\n",
        "\n",
        "    # State\n",
        "    chat_messages = []  # list of dicts\n",
        "    query_embed_cache = {}\n",
        "\n",
        "    def get_embedding(text):\n",
        "        key = text[:2000]\n",
        "        if key in query_embed_cache:\n",
        "            return query_embed_cache[key]\n",
        "        resp = client.embeddings.create(model=\"text-embedding-3-small\", input=text if text else \"\")\n",
        "        arr = np.array(resp.data[0].embedding, dtype=np.float32)\n",
        "        query_embed_cache[key] = arr\n",
        "        return arr\n",
        "\n",
        "    def current_system_prompt():\n",
        "        bias = bias_input.value.strip()\n",
        "        if bias:\n",
        "            return f\"{system_prompt_input.value}\\nBias theme: {bias}\"\n",
        "        return system_prompt_input.value\n",
        "\n",
        "    def update_chat_display():\n",
        "        safe_prompt = html.escape(current_system_prompt())\n",
        "        display(HTML(f\"\"\"\n",
        "        <div style='position:sticky; top:0; background:#222; color:#fff; padding:8px; border-bottom:2px solid #555; z-index:10;'>\n",
        "          üìù <b>System Prompt:</b> {safe_prompt} | üîë <b>API Key:</b> ‚úÖ Active\n",
        "        </div>\n",
        "        <div style='max-height:420px; overflow-y:auto; border:1px solid #444; background:#111; color:#ddd; padding:10px; border-radius:8px;'>\n",
        "          {chat_history_html}\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "    def pick_top_entries(user_text, top_k, kw_weight):\n",
        "        q_emb = get_embedding(user_text)\n",
        "        sims = cosine_similarity([q_emb], summary_embeddings)[0]\n",
        "        ents = extract_entities(user_text)\n",
        "        kw_scores = np.array([keyword_score(e, ents) for e in kb], dtype=np.float32)\n",
        "        combined = sims + kw_weight * (kw_scores / (kw_scores.max() if kw_scores.max() > 0 else 1.0))\n",
        "        idxs = np.argsort(combined)[-top_k:][::-1]\n",
        "        return [idx for idx in idxs], combined\n",
        "\n",
        "    def safe_html(s):\n",
        "        return html.escape(s).replace(\"\\n\", \"<br>\")\n",
        "\n",
        "    def on_send(_):\n",
        "        global chat_history_html\n",
        "        user_input = text_input.value.strip()\n",
        "        text_input.value = \"\"\n",
        "        if not user_input:\n",
        "            return\n",
        "\n",
        "        if ocr_checkbox.value:\n",
        "            maybe_install_ocr_deps()\n",
        "\n",
        "        top_k = top_k_slider.value\n",
        "        kw_w = kw_weight_slider.value\n",
        "        ctx_chars = ctx_chars_slider.value\n",
        "\n",
        "        top_idxs, combined = pick_top_entries(user_input, top_k=top_k, kw_weight=kw_w)\n",
        "        selected_entries = [kb[i] for i in top_idxs]\n",
        "\n",
        "        for i in top_idxs:\n",
        "            entry = kb[i]\n",
        "            title = entry.get('title') or entry.get('name') or 'Untitled'\n",
        "            date = entry.get('date') or entry.get('datePublished') or ''\n",
        "            url = entry.get('url') or entry.get('pdf') or entry.get('link') or ''\n",
        "            summ = summaries[i][:300] + (\"...\" if len(summaries[i]) > 300 else \"\")\n",
        "            url_html = f\"<a href='{html.escape(url)}' target='_blank' style='color:#1e90ff;'>Open</a>\" if url else \"<i>No link</i>\"\n",
        "            chat_history_html += f\"\"\"\n",
        "            <div style='background:#333; padding:8px; margin:6px 0; border-radius:6px;'>\n",
        "              üìÑ <b>{html.escape(title)}</b> {f\"({html.escape(str(date))})\" if date else \"\"}<br>\n",
        "              <i>{html.escape(summ)}</i><br>\n",
        "              {url_html}\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        texts = []\n",
        "        for e in selected_entries:\n",
        "            url = e.get('url') or e.get('pdf') or e.get('link') or ''\n",
        "            doc_text = fetch_pdf_text(url, try_ocr=ocr_checkbox.value) if url else \"\"\n",
        "            if isinstance(doc_text, str) and len(doc_text) > ctx_chars:\n",
        "                doc_text = doc_text[:ctx_chars] + f\"\\n[Truncated to {ctx_chars} characters]\"\n",
        "            texts.append(doc_text)\n",
        "\n",
        "        combined_pdf_text = \"\\n\\n---\\n\\n\".join(texts)\n",
        "\n",
        "        user_message = {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Relevant PDF Content:\\n{combined_pdf_text}\\n\\nUser Question: {user_input}\"\n",
        "        }\n",
        "        chat_messages.append(user_message)\n",
        "\n",
        "        conversation_history = [{\"role\": \"system\", \"content\": current_system_prompt()}] + chat_messages\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4o-mini\",\n",
        "                messages=conversation_history,\n",
        "                max_tokens=700,\n",
        "                temperature=0.7,\n",
        "            )\n",
        "            assistant_msg = response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            assistant_msg = f\"‚ö†Ô∏è API Error: {e}\"\n",
        "\n",
        "        chat_messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "\n",
        "        chat_history_html += f\"\"\"\n",
        "        <div style='background:#222; padding:8px; margin:6px 0; border-radius:6px;'>\n",
        "          <b style='color:#ffdd57;'>Assistant:</b><br>{safe_html(assistant_msg)}\n",
        "        </div>\n",
        "        \"\"\"\n",
        "\n",
        "        update_chat_display()\n",
        "        if show_mem_checkbox.value:\n",
        "            print_memory_usage(conversation_history)\n",
        "\n",
        "    text_input = widgets.Text(placeholder='Type your question here...')\n",
        "    send_button = widgets.Button(description='Send', button_style='success')\n",
        "    send_button.on_click(on_send)\n",
        "    clear_button = widgets.Button(description='Clear Chat', button_style='danger')\n",
        "\n",
        "    def on_clear(_):\n",
        "        global chat_history_html\n",
        "        chat_history_html = \"\"\n",
        "        chat_messages.clear()\n",
        "        update_chat_display()\n",
        "    clear_button.on_click(on_clear)\n",
        "\n",
        "    controls = widgets.HBox([top_k_slider, kw_weight_slider, ctx_chars_slider, ocr_checkbox, show_mem_checkbox])\n",
        "    update_chat_display()\n",
        "    display(widgets.VBox([bias_input, system_prompt_input, controls, widgets.HBox([text_input, send_button, clear_button])]))\n",
        "\n",
        "# ----------------------------\n",
        "# Proceed gate\n",
        "# ----------------------------\n",
        "proceed_button = widgets.Button(description='Proceed', button_style='primary')\n",
        "proceed_out = widgets.Output()\n",
        "\n",
        "def proceed(_):\n",
        "    with proceed_out:\n",
        "        clear_output()\n",
        "        if not api_key_ready and not os.getenv(\"OPENAI_API_KEY\"):\n",
        "            display(HTML(\"<b style='color:#e53935;'>‚ùå Please save your API key first.</b>\"))\n",
        "            return\n",
        "        try:\n",
        "            kb = upload_json()\n",
        "            summaries, summary_embeddings = create_embeddings(kb)\n",
        "            chat_ui(kb, summaries, summary_embeddings)\n",
        "        except Exception as e:\n",
        "            display(HTML(f\"<b style='color:#e53935;'>‚ö†Ô∏è Error:</b> {html.escape(str(e))}\"))\n",
        "\n",
        "display(HTML(\"<h3>‚ñ∂Ô∏è When your API key shows as saved, click Proceed:</h3>\"))\n",
        "display(proceed_button, proceed_out)\n",
        "proceed_button.on_click(proceed)\n",
        "\n"
      ]
    }
  ]
}